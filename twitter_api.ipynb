{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import tweepy\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# API keyws that yous saved earlier\n",
    "api_key       = \"NSwkzeZPs4Siuv2aMMUZkOM7k\"\n",
    "api_secrets   = \"bOXvfq9BoKPl6vIYaLKMXeqqSE6zDdEcJcOgIY7zYQQpz912mZ\"\n",
    "access_token  = \"1567881743847268352-ZluwBxepbzjhfo77UGS24THYNGKHwq\"\n",
    "access_secret = \"fDhpymBmrPWmbvagOFdN2A1OGmEueSqWdVwNCwzz10sS6\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successful Authentication\n"
     ]
    }
   ],
   "source": [
    "# Authenticate to Twitter\n",
    "auth = tweepy.OAuthHandler(api_key,api_secrets)\n",
    "auth.set_access_token(access_token,access_secret)\n",
    " \n",
    "api = tweepy.API(auth)\n",
    " \n",
    "try:\n",
    "    api.verify_credentials()\n",
    "    print('Successful Authentication')\n",
    "except:\n",
    "    print('Failed authentication')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to display data of each tweet\n",
    "def printtweetdata(n, ith_tweet):\n",
    "\tprint()\n",
    "\tprint(f\"Tweet {n}:\")\n",
    "\tprint(f\"Username:{ith_tweet[0]}\")\n",
    "\tprint(f\"Description:{ith_tweet[1]}\")\n",
    "\tprint(f\"Location:{ith_tweet[2]}\")\n",
    "\tprint(f\"Following Count:{ith_tweet[3]}\")\n",
    "\tprint(f\"Follower Count:{ith_tweet[4]}\")\n",
    "\tprint(f\"Total Tweets:{ith_tweet[5]}\")\n",
    "\tprint(f\"Retweet Count:{ith_tweet[6]}\")\n",
    "\tprint(f\"Tweet Text:{ith_tweet[7]}\")\n",
    "\tprint(f\"Hashtags Used:{ith_tweet[8]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to perform data extraction\n",
    "def scrape_by_hashtag(hashtag, date_since, numtweet, filename = 'scraped_tweets.csv'):\n",
    "\n",
    "\t# Creating DataFrame using pandas\n",
    "\tdb = pd.DataFrame(columns=['username', 'description', 'location', 'text', 'hashtags'])\n",
    "\n",
    "\t# We are using .Cursor() to search through twitter \n",
    "\t# for the required tweets. The number of tweets can be\n",
    "\t# restricted using .items(number of tweets)\n",
    "\ttweets = tweepy.Cursor(api.search_tweets, q = hashtag, lang=\"en\",\n",
    "\t\t\t\t\t\tsince_id=date_since, tweet_mode='extended').items(numtweet)\n",
    "\n",
    "\n",
    "\t# .Cursor() returns an iterable object. Each item in\n",
    "\t# the iterator has various attributes that you can \n",
    "\t# access to get information about each tweet\n",
    "\tlist_tweets = [tweet for tweet in tweets]\n",
    "\n",
    "\t# Counter to maintain Tweet Count\n",
    "\ti = 1\n",
    "\n",
    "\t# we will iterate over each tweet in the\n",
    "\t# list for extracting information about each tweet\n",
    "\tfor tweet in list_tweets:\n",
    "\t\tusername     = tweet.user.screen_name\n",
    "\t\tdescription  = tweet.user.description\n",
    "\t\tlocation     = tweet.user.location\n",
    "\t\thashtags     = tweet.entities['hashtags']\n",
    "\n",
    "\t\t# Retweets can be distinguished by a retweeted_status attribute,\n",
    "\t\t# in case it is an invalid reference, except block will be executed\n",
    "\t\ttry:\n",
    "\t\t\ttext = tweet.retweeted_status.full_text\n",
    "\t\texcept AttributeError:\n",
    "\t\t\ttext = tweet.full_text\n",
    "\t\thashtext = list()\n",
    "\t\tfor j in range(0, len(hashtags)):\n",
    "\t\t\thashtext.append(hashtags[j]['text'])\n",
    "\n",
    "\t\t# Here we are appending all the\n",
    "\t\t# extracted information in the DataFrame\n",
    "\t\tith_tweet = [username, description, location, text, hashtext]\n",
    "\t\tdb.loc[len(db)] = ith_tweet\n",
    "\n",
    "\n",
    "\t# we will save our database as a CSV file.\n",
    "\tdb.to_csv(filename)\n",
    "\treturn db\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_df = scrape_by_hashtag(\"#vcu\", \"2022-09-01\", 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>username</th>\n",
       "      <th>description</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>hashtags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RowdyRams</td>\n",
       "      <td>2013 Naismith Student Section of the Year! The...</td>\n",
       "      <td>VCU, Richmond, VA</td>\n",
       "      <td>Women‚Äôs Soccer Finalüñ§üíõ\\n\\nVCU-1\\nUMASS-1\\n\\n#VCUüêè</td>\n",
       "      <td>[VCU]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LaughOutNOW</td>\n",
       "      <td>Comedy College began in 1999, is home to \"Stan...</td>\n",
       "      <td>Milwaukee-Chicago</td>\n",
       "      <td>$7.99 Standup Comedy career launcher workbook-...</td>\n",
       "      <td>[dirty, racing, sos, lsu, tigers, maryland, wv...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MIKEALIS</td>\n",
       "      <td>DJüéö Thursday‚Äôs @ SINE‚Äô | Friday's @ SINE' |  b...</td>\n",
       "      <td>Richmond, VA</td>\n",
       "      <td>9.15.22 #SineThirstdays üçÄü™©üíÉüèª\\n\\nCollege night ...</td>\n",
       "      <td>[SineThirstdays, RVA, VCU]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BarnesWriters</td>\n",
       "      <td>We help you to boost grades for your Essays. A...</td>\n",
       "      <td>Global Assignment Help</td>\n",
       "      <td>Need help with any of your assignments, essays...</td>\n",
       "      <td>[fvsu, VSU, SSU, myasu, cau, GSU, Spelman, SSU...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>VCUHSLibrary</td>\n",
       "      <td>VCU Health Sciences Library is a comprehensive...</td>\n",
       "      <td>Richmond, VA</td>\n",
       "      <td>The card catalog, seen here in 1970, facilitat...</td>\n",
       "      <td>[VCUHSL90Years, VCU]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>VeridianCU</td>\n",
       "      <td>At Veridian, we partner with our members to cr...</td>\n",
       "      <td>Iowa</td>\n",
       "      <td>Not even rain can stop our volunteers this pas...</td>\n",
       "      <td>[VCU, ShredDay]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>VCUPD</td>\n",
       "      <td>Providing a safe learning, living &amp; working en...</td>\n",
       "      <td>Richmond, Virginia</td>\n",
       "      <td>üñ§üíõ RamStrong is a collective health and well-b...</td>\n",
       "      <td>[VCU]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>WriterYvonne</td>\n",
       "      <td>#gramfamüêµ ‚ùÑmusicüíØ loverüéº #blacklivesmatter  #l...</td>\n",
       "      <td>United States</td>\n",
       "      <td>Essays‚úì.    \\n    Discussion post‚úì\\n    Annota...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>ChicagoEssays</td>\n",
       "      <td>Email :Info.chicagoessays@gmail.com           ...</td>\n",
       "      <td>Online class/ homework help</td>\n",
       "      <td>Get online class homework exam help \\n\\nThesis...</td>\n",
       "      <td>[pvamu, ncat, nccu, AAMU, Alcorn, SSU, Gramfam...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>ZeroPlagiarism</td>\n",
       "      <td>EMAIL: ozeroplagiarism@gmail.com.             ...</td>\n",
       "      <td>24hr Assignment Help Service</td>\n",
       "      <td>Get online class homework exam help \\n\\nThesis...</td>\n",
       "      <td>[pvamu, ncat, nccu, AAMU, Alcorn, SSU, Gramfam...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         username                                        description  \\\n",
       "0       RowdyRams  2013 Naismith Student Section of the Year! The...   \n",
       "1     LaughOutNOW  Comedy College began in 1999, is home to \"Stan...   \n",
       "2        MIKEALIS  DJüéö Thursday‚Äôs @ SINE‚Äô | Friday's @ SINE' |  b...   \n",
       "3   BarnesWriters  We help you to boost grades for your Essays. A...   \n",
       "4    VCUHSLibrary  VCU Health Sciences Library is a comprehensive...   \n",
       "5      VeridianCU  At Veridian, we partner with our members to cr...   \n",
       "6           VCUPD  Providing a safe learning, living & working en...   \n",
       "7    WriterYvonne  #gramfamüêµ ‚ùÑmusicüíØ loverüéº #blacklivesmatter  #l...   \n",
       "8   ChicagoEssays  Email :Info.chicagoessays@gmail.com           ...   \n",
       "9  ZeroPlagiarism  EMAIL: ozeroplagiarism@gmail.com.             ...   \n",
       "\n",
       "                       location  \\\n",
       "0             VCU, Richmond, VA   \n",
       "1             Milwaukee-Chicago   \n",
       "2                  Richmond, VA   \n",
       "3        Global Assignment Help   \n",
       "4                  Richmond, VA   \n",
       "5                          Iowa   \n",
       "6            Richmond, Virginia   \n",
       "7                 United States   \n",
       "8   Online class/ homework help   \n",
       "9  24hr Assignment Help Service   \n",
       "\n",
       "                                                text  \\\n",
       "0  Women‚Äôs Soccer Finalüñ§üíõ\\n\\nVCU-1\\nUMASS-1\\n\\n#VCUüêè   \n",
       "1  $7.99 Standup Comedy career launcher workbook-...   \n",
       "2  9.15.22 #SineThirstdays üçÄü™©üíÉüèª\\n\\nCollege night ...   \n",
       "3  Need help with any of your assignments, essays...   \n",
       "4  The card catalog, seen here in 1970, facilitat...   \n",
       "5  Not even rain can stop our volunteers this pas...   \n",
       "6  üñ§üíõ RamStrong is a collective health and well-b...   \n",
       "7  Essays‚úì.    \\n    Discussion post‚úì\\n    Annota...   \n",
       "8  Get online class homework exam help \\n\\nThesis...   \n",
       "9  Get online class homework exam help \\n\\nThesis...   \n",
       "\n",
       "                                            hashtags  \n",
       "0                                              [VCU]  \n",
       "1  [dirty, racing, sos, lsu, tigers, maryland, wv...  \n",
       "2                         [SineThirstdays, RVA, VCU]  \n",
       "3  [fvsu, VSU, SSU, myasu, cau, GSU, Spelman, SSU...  \n",
       "4                               [VCUHSL90Years, VCU]  \n",
       "5                                    [VCU, ShredDay]  \n",
       "6                                              [VCU]  \n",
       "7                                                 []  \n",
       "8  [pvamu, ncat, nccu, AAMU, Alcorn, SSU, Gramfam...  \n",
       "9  [pvamu, ncat, nccu, AAMU, Alcorn, SSU, Gramfam...  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.5 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8bfc27490fa1961d11913dd213748aabeee9b5ee1ac81d5737fca599705f453b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
